/**
 * Data Ingestion Orchestrator
 * Main entry point for multi-source data collection
 */

import * as cron from 'node-cron';
import * as dotenv from 'dotenv';
import * as path from 'path';

dotenv.config({ path: path.join(__dirname, '../../../.env') });

import { config, validateConfig } from './config';
import { collectTwitterData } from './sources/twitter';
import { collectEpicData } from './sources/epic';
import { collectFortniteApiData } from './sources/fortnite-api';
import { collectRedditData } from './sources/reddit';
import { collectNewsData } from './sources/news';
import { deduplicateRecords, pruneRecords, normalizeRecords } from './normalizer';
import { initializeStorage, loadRecords, saveRecords, logIngestion } from './writer';
import { IngestionResult, FortniteRecord } from './types';

let isRunning = false;

export async function runIngestion(): Promise<IngestionResult[]> {
  if (isRunning) {
    console.log('âš ï¸  Ingestion already in progress, skipping...');
    return [];
  }

  isRunning = true;
  console.log('\nðŸš€ Starting data ingestion...');
  console.log(`â° ${new Date().toLocaleString()}\n`);

  const results: IngestionResult[] = [];
  const allNewRecords: FortniteRecord[] = [];

  try {
    // Initialize storage
    await initializeStorage();

    // Collect from all sources in parallel
    const sources = [
      { name: 'Twitter', fn: collectTwitterData, source: 'twitter' as const },
      { name: 'Epic CMS', fn: collectEpicData, source: 'epic' as const },
      { name: 'Fortnite-API', fn: collectFortniteApiData, source: 'fortnite-api' as const },
      { name: 'Reddit', fn: collectRedditData, source: 'reddit' as const },
      { name: 'News RSS', fn: collectNewsData, source: 'news' as const },
    ];

    for (const { name, fn, source } of sources) {
      try {
        console.log(`ðŸ“¡ ${name}:`);
        const records = await fn();
        
        const normalized = normalizeRecords(records);
        allNewRecords.push(...normalized);

        results.push({
          source,
          success: true,
          newRecords: normalized.length,
          totalFetched: records.length,
          timestamp: new Date().toISOString(),
        });
      } catch (error) {
        console.error(`âŒ ${name} failed:`, error);
        results.push({
          source,
          success: false,
          newRecords: 0,
          totalFetched: 0,
          error: error instanceof Error ? error.message : 'Unknown error',
          timestamp: new Date().toISOString(),
        });
      }
    }

    // Load existing records
    console.log('\nðŸ“š Processing records...');
    const existingRecords = await loadRecords();
    console.log(`  ðŸ“¦ Existing records: ${existingRecords.length}`);
    console.log(`  ðŸ†• Fetched records: ${allNewRecords.length}`);

    // Deduplicate
    const { merged, newCount } = deduplicateRecords(existingRecords, allNewRecords);
    console.log(`  âœ¨ New unique records: ${newCount}`);

    // Prune old records
    const final = pruneRecords(merged, config.maxRecords);

    // Save to disk
    await saveRecords(final);

    // Log results
    await logIngestion(results);

    // Summary
    console.log('\nðŸ“Š Ingestion Summary:');
    console.log(`  âœ… Successful sources: ${results.filter(r => r.success).length}/${results.length}`);
    console.log(`  ðŸ†• New records added: ${newCount}`);
    console.log(`  ðŸ’¾ Total records stored: ${final.length}`);
    console.log(`  ðŸ—„ï¸  Storage: ${config.recordsFile}`);

  } catch (error) {
    console.error('\nâŒ Ingestion failed:', error);
  } finally {
    isRunning = false;
    console.log(`\nâœ… Ingestion complete at ${new Date().toLocaleString()}\n`);
  }

  return results;
}

export function startScheduledIngestion(): void {
  console.log('ðŸ”„ Starting scheduled data ingestion...');
  console.log(`â° Schedule: ${config.cronSchedule} (every 10 minutes)`);
  
  // Show config warnings
  const warnings = validateConfig();
  if (warnings.length > 0) {
    console.log('\nâš ï¸  Configuration warnings:');
    warnings.forEach(w => console.log(`  - ${w}`));
  }

  // Run immediately on start
  console.log('\nðŸš€ Running initial ingestion...\n');
  runIngestion().catch(console.error);

  // Schedule recurring ingestion
  cron.schedule(config.cronSchedule, () => {
    runIngestion().catch(console.error);
  });

  console.log('\nâœ… Scheduler started. Press Ctrl+C to stop.\n');
}

// Export for use in other packages
export * from './types';
export { loadRecords, saveRecords } from './writer';

// Run if executed directly
if (require.main === module) {
  const args = process.argv.slice(2);
  
  if (args.includes('--once')) {
    // Run once and exit
    runIngestion()
      .then(() => process.exit(0))
      .catch((error) => {
        console.error(error);
        process.exit(1);
      });
  } else {
    // Run on schedule
    startScheduledIngestion();
  }
}
